{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulhuangkm/MiniASR/blob/main/example/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc6s2gOOlg-W"
      },
      "source": [
        "# **MiniASR Tutorial: LibriSpeech Training**\n",
        "This is a tutorial for training an end-to-end automatic speech recognition model with the toolkit [MiniASR](https://github.com/vectominist/MiniASR).  \n",
        "You can run this notebook on [Google Colab](colab.research.google.com/), but to train an ASR model completely requires a Pro account since it needs several hours to converge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHy3V7O_lu-d"
      },
      "source": [
        "## **Download Code & Install Dependencies**\n",
        "Ref: [MiniASR](https://github.com/vectominist/MiniASR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3ZxMQbvk25k"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/paulhuangkm/MiniASR.git\n",
        "% cd MiniASR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf7QLclNieZx"
      },
      "outputs": [],
      "source": [
        "! pip3 install -e ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld5EZj6_mnH5"
      },
      "source": [
        "## **Download Data**\n",
        "- training set: [Libri-light](https://github.com/facebookresearch/libri-light) fine-tuning set (10 hours, 0.6G)\n",
        "- development set: [LibriSpeech](https://www.openslr.org/12) `dev-clean` set\n",
        "- testing set: [LibriSpeech](https://www.openslr.org/12) `test-clean` set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Nmh3oywnAgZ"
      },
      "outputs": [],
      "source": [
        "! mkdir -p data\n",
        "% cd data\n",
        "! wget https://dl.fbaipublicfiles.com/librilight/data/librispeech_finetuning.tgz\n",
        "! tar zxf librispeech_finetuning.tgz\n",
        "! rm librispeech_finetuning.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6BIVK1knUTK"
      },
      "outputs": [],
      "source": [
        "! wget https://www.openslr.org/resources/12/dev-clean.tar.gz\n",
        "! wget https://www.openslr.org/resources/12/test-clean.tar.gz\n",
        "! tar zxf dev-clean.tar.gz\n",
        "! tar zxf test-clean.tar.gz\n",
        "! rm dev-clean.tar.gz\n",
        "! rm test-clean.tar.gz\n",
        "% cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-hzi6-o0ze"
      },
      "source": [
        "## **Preprocess Data**\n",
        "Find all data in the corpus and extract vocabularies. We use characters as text tokens since the dataset is small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWWcTzXho4b3"
      },
      "outputs": [],
      "source": [
        "# Train set\n",
        "! miniasr-preprocess \\\n",
        "        -c LibriSpeech \\\n",
        "        -p data/librispeech_finetuning \\\n",
        "        -s 1h \\\n",
        "        -o data/libri_train_1h \\\n",
        "        --gen-vocab \\\n",
        "        --char-vocab-size 40\n",
        "\n",
        "! miniasr-preprocess \\\n",
        "        -c LibriSpeech \\\n",
        "        -p data/librispeech_finetuning \\\n",
        "        -s 9h \\\n",
        "        -o data/libri_train_9h\n",
        "\n",
        "# Development set\n",
        "! miniasr-preprocess \\\n",
        "        -c LibriSpeech \\\n",
        "        -p data/LibriSpeech \\\n",
        "        -s dev-clean \\\n",
        "        -o data/libri_dev\n",
        "\n",
        "# Test set\n",
        "! miniasr-preprocess \\\n",
        "        -c LibriSpeech \\\n",
        "        -p data/LibriSpeech \\\n",
        "        -s test-clean \\\n",
        "        -o data/libri_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcyY1IWMrezU"
      },
      "source": [
        "## **Training**\n",
        "- Modify `MiniASR/egs/librispeech/config/ctc_train_example.yaml` for changing training hyper-parameters.\n",
        "- The results will be saved to `MiniASR/model/ctc_libri-10h_char`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDENJR7Wq7pN"
      },
      "outputs": [],
      "source": [
        "! mkdir -p model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTBUATPSsXsh",
        "outputId": "e09ddbd8-d41d-459f-f769-739aacfe09de"
      },
      "outputs": [],
      "source": [
        "! minasr-asr --config egs/librispeech/config/con_ctc.yaml\n",
        "\n",
        "# Resume training with this command:\n",
        "# ! minasr-asr --ckpt model/con_libri-10h_char/epoch=4-step=429.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVXy9YUVuLpt"
      },
      "source": [
        "## **Testing**\n",
        "- Specify your checkpoint with `--ckpt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3B1mCCKuOYl",
        "outputId": "fe244d16-6eeb-469a-b663-80afd04f3e01"
      },
      "outputs": [],
      "source": [
        "! minasr-asr \\\n",
        "    --config egs/librispeech/config/con_ctc_test.yaml \\\n",
        "    --test \\\n",
        "    --override \"args.data.dev_paths=['data/libri_test/data_list_sorted.json']\" \\\n",
        "    --ckpt model/con_libri-10h_char/epoch=44-step=3869.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTjPqeq-EIh8"
      },
      "source": [
        "## **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99pGiNgrRNSZ"
      },
      "outputs": [],
      "source": [
        "from miniasr.utils import load_from_checkpoint, sequence_distance\n",
        "from miniasr.data.audio import load_waveform\n",
        "\n",
        "model, args, tokenizer = load_from_checkpoint(\n",
        "    'model/ctc_libri-10h_char/epoch=44-step=3869.ckpt', 'cuda')\n",
        "waves = [load_waveform('data/LibriSpeech/dev-clean/6345/93302/6345-93302-0025.flac').to('cuda')]\n",
        "hyps = model.recognize(waves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UazYyxmZSKOQ",
        "outputId": "9b56a5cc-6e36-41a6-a730-75eeb0558717"
      },
      "outputs": [],
      "source": [
        "print(hyps[0])\n",
        "ref = 'ARE YOU REALLY GOING TO THROW ME OVER FOR A THING LIKE THIS'\n",
        "res_cer = sequence_distance(ref, hyps[0], mode='char')\n",
        "res_wer = sequence_distance(ref, hyps[0], mode='word')\n",
        "print('CER = {:.2f}%'.format(100. * res_cer['distance'] / res_cer['length']))\n",
        "print('WER = {:.2f}%'.format(100. * res_wer['distance'] / res_wer['length']))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "OHy3V7O_lu-d",
        "Ld5EZj6_mnH5",
        "Zx-hzi6-o0ze"
      ],
      "include_colab_link": true,
      "name": "example_librispeech_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
